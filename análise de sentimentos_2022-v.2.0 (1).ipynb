{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4a9439",
   "metadata": {},
   "source": [
    "# Instalação dos módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadc0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter-v2 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (0.7.9)\n",
      "Requirement already satisfied: requests<3.0,>=2.24 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from python-twitter-v2) (2.28.1)\n",
      "Requirement already satisfied: Authlib<0.16.0,>=0.15.4 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from python-twitter-v2) (0.15.6)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.2 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from python-twitter-v2) (0.5.7)\n",
      "Requirement already satisfied: cryptography in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from Authlib<0.16.0,>=0.15.4->python-twitter-v2) (37.0.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (0.8.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (3.18.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.24->python-twitter-v2) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.24->python-twitter-v2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.24->python-twitter-v2) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.24->python-twitter-v2) (2022.9.14)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (4.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from cryptography->Authlib<0.16.0,>=0.15.4->python-twitter-v2) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->Authlib<0.16.0,>=0.15.4->python-twitter-v2) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.2->python-twitter-v2) (3.0.9)\n",
      "Requirement already satisfied: snscrape in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (0.4.3.20220106)\n",
      "Requirement already satisfied: filelock in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from snscrape) (3.6.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from snscrape) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from snscrape) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-twitter-v2\n",
    "!pip install snscrape\n",
    "!pip install nltk\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c5095",
   "metadata": {},
   "source": [
    "# Obtendo os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7d21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as dados\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60fa2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_twittes_bolsonaro = []\n",
    "lista_twittes_lula = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aef48855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = datetime.date.today()\n",
    "data_inicial = '2022-7-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ac0834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kai-q\\AppData\\Local\\Temp\\ipykernel_5740\\2838122764.py:4: FutureWarning: username is deprecated, use user.username instead\n",
      "  lista_twittes_bolsonaro.append([tweet.date, tweet.id, tweet.content, tweet.username])\n"
     ]
    }
   ],
   "source": [
    "for i,tweet in enumerate(dados.TwitterSearchScraper(f'{\"Bolsonaro\"} + since:{data_inicial} until:{data_final}').get_items()):\n",
    "    if i>500:\n",
    "        break\n",
    "    lista_twittes_bolsonaro.append([tweet.date, tweet.id, tweet.content, tweet.username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e657e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kai-q\\AppData\\Local\\Temp\\ipykernel_5740\\3883585577.py:4: FutureWarning: username is deprecated, use user.username instead\n",
      "  lista_twittes_lula.append([tweet.date, tweet.id, tweet.content, tweet.username])\n"
     ]
    }
   ],
   "source": [
    "for i,tweet in enumerate(dados.TwitterSearchScraper(f'{\"Lula\"} + since:{data_inicial} until:{data_final}').get_items()):\n",
    "    if i>500:\n",
    "        break\n",
    "    lista_twittes_lula.append([tweet.date, tweet.id, tweet.content, tweet.username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4dcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bolsonaro = pd.DataFrame(lista_twittes_bolsonaro, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "df_lula = pd.DataFrame(lista_twittes_lula, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19badfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_bolsonaro, df_lula, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5e319b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2022-11-08 23:59:49+00:00</td>\n",
       "      <td>1590132013579010048</td>\n",
       "      <td>@LulaOficial Pra mim tanto faz pedi demissão d...</td>\n",
       "      <td>cassanelli3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2022-11-08 23:57:58+00:00</td>\n",
       "      <td>1590131546107056128</td>\n",
       "      <td>Se o Lula indicar a Joenia Wapichana vocês não...</td>\n",
       "      <td>munixleitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2022-11-08 23:59:56+00:00</td>\n",
       "      <td>1590132039977955328</td>\n",
       "      <td>Esquece! Agora que o coiso não sai mais do Pal...</td>\n",
       "      <td>LeneCarafini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2022-11-08 23:58:27+00:00</td>\n",
       "      <td>1590131669792878592</td>\n",
       "      <td>@AndreJanonesAdv Danone o Carlos bolsonaro lhe...</td>\n",
       "      <td>JuracyOliveira9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-08 23:59:56+00:00</td>\n",
       "      <td>1590132040489312256</td>\n",
       "      <td>@JoseSil34113719 @geraldoalckmin @LulaOficial ...</td>\n",
       "      <td>dougmoreira_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2022-11-08 23:57:08+00:00</td>\n",
       "      <td>1590131338451251201</td>\n",
       "      <td>@pedropedrinho0o @httphelioJ Nem estratégia po...</td>\n",
       "      <td>Sapo_pepe77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2022-11-08 23:58:21+00:00</td>\n",
       "      <td>1590131642101702656</td>\n",
       "      <td>@LulaOficial @ricardostuckert Meu presidente</td>\n",
       "      <td>FranUmbelino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2022-11-08 23:58:10+00:00</td>\n",
       "      <td>1590131594508918784</td>\n",
       "      <td>@PamellaMonique_ @JoaquinTeixeira @PATRlOTAS @...</td>\n",
       "      <td>Bolsonaro22P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>2022-11-08 23:58:11+00:00</td>\n",
       "      <td>1590131601119547392</td>\n",
       "      <td>@quenanileal @thiguilherme Teste de Geringonça...</td>\n",
       "      <td>socialismomao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2022-11-08 23:55:34+00:00</td>\n",
       "      <td>1590130940441153536</td>\n",
       "      <td>@thinkmoreBrazil ou seja eh um Bolsonaro 2.0</td>\n",
       "      <td>LuanSouzaSant14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Datetime             Tweet Id  \\\n",
       "538 2022-11-08 23:59:49+00:00  1590132013579010048   \n",
       "900 2022-11-08 23:57:58+00:00  1590131546107056128   \n",
       "517 2022-11-08 23:59:56+00:00  1590132039977955328   \n",
       "129 2022-11-08 23:58:27+00:00  1590131669792878592   \n",
       "3   2022-11-08 23:59:56+00:00  1590132040489312256   \n",
       "238 2022-11-08 23:57:08+00:00  1590131338451251201   \n",
       "824 2022-11-08 23:58:21+00:00  1590131642101702656   \n",
       "152 2022-11-08 23:58:10+00:00  1590131594508918784   \n",
       "858 2022-11-08 23:58:11+00:00  1590131601119547392   \n",
       "363 2022-11-08 23:55:34+00:00  1590130940441153536   \n",
       "\n",
       "                                                  Text         Username  \n",
       "538  @LulaOficial Pra mim tanto faz pedi demissão d...      cassanelli3  \n",
       "900  Se o Lula indicar a Joenia Wapichana vocês não...      munixleitor  \n",
       "517  Esquece! Agora que o coiso não sai mais do Pal...     LeneCarafini  \n",
       "129  @AndreJanonesAdv Danone o Carlos bolsonaro lhe...  JuracyOliveira9  \n",
       "3    @JoseSil34113719 @geraldoalckmin @LulaOficial ...     dougmoreira_  \n",
       "238  @pedropedrinho0o @httphelioJ Nem estratégia po...      Sapo_pepe77  \n",
       "824       @LulaOficial @ricardostuckert Meu presidente     FranUmbelino  \n",
       "152  @PamellaMonique_ @JoaquinTeixeira @PATRlOTAS @...     Bolsonaro22P  \n",
       "858  @quenanileal @thiguilherme Teste de Geringonça...    socialismomao  \n",
       "363       @thinkmoreBrazil ou seja eh um Bolsonaro 2.0  LuanSouzaSant14  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed49728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "     -------------------------------------- 636.8/636.8 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "Requirement already satisfied: unidecode in c:\\users\\kai-q\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b42437d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from unidecode import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Demonstrates how to make a simple call to the Natural Language API.\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "from google.cloud import language_v1\n",
    "\n",
    "def print_result(annotations):\n",
    "    score = annotations.document_sentiment.score\n",
    "    magnitude = annotations.document_sentiment.magnitude\n",
    "\n",
    "    for index, sentence in enumerate(annotations.sentences):\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        print(\n",
    "            \"Sentence {} has a sentiment score of {}\".format(index, sentence_sentiment)\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"Overall Sentiment: score of {} with magnitude of {}\".format(score, magnitude)\n",
    "    )\n",
    "    return 0\n",
    "\n",
    "def analyze(movie_review_filename):\n",
    "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    with open(movie_review_filename, \"r\") as review_file:\n",
    "        # Instantiates a plain text document.\n",
    "        content = review_file.read()\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "    annotations = client.analyze_sentiment(request={\"document\": document})\n",
    "\n",
    "    # Print the results\n",
    "    print_result(annotations)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"movie_review_filename\",\n",
    "        help=\"The filename of the movie review you'd like to analyze.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    analyze(args.movie_review_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "babd2792",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Constants' from 'googletrans' (C:\\Users\\kai-q\\anaconda3\\lib\\site-packages\\googletrans\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5740\\1876455343.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogletrans\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConstants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtranslator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Constants' from 'googletrans' (C:\\Users\\kai-q\\anaconda3\\lib\\site-packages\\googletrans\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator, Constants\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3219519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contadores de sentimentos positivos e negativos\n",
    "numPos = 0\n",
    "numNeg = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c416ade2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      @fernandobassi Vc descreveu a Michelle. Serio!...\n",
       "1      @ariellediasbr Um cara bom de alvo, faria ele ...\n",
       "2      O tom condescendente da midia querendo humaniz...\n",
       "3      @JoseSil34113719 @geraldoalckmin @LulaOficial ...\n",
       "4                                         @SilvinaRamal \n",
       "                             ...                        \n",
       "496    @jandira_feghali Mulher, vai se tratar! Vc e d...\n",
       "497         @Rconstantino @RrGraci Quem comeu o  de quem\n",
       "498    @rodrigopacheco Quem e TCU para atestar isso??...\n",
       "499    @marcelo_lopes67 @EdRaposo_ Eu tbm. Espero do ...\n",
       "500                              @marcosbalbi1 Belezura!\n",
       "Name: Text, Length: 501, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Aplicando unidecode aos textos do Tweet\n",
    "textPT = df_bolsonaro['Text'].apply(unidecode)\n",
    "display(textPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a10176",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from googletrans import Translator\n",
    ">>> translator = Translator()\n",
    ">>> translator.translate('textPT')\n",
    "# <Translated src=ko dest=en text=Good evening. pronunciation=Good evening.>\n",
    ">>> translator.translate('안녕하세요.', dest='ja')\n",
    "# <Translated src=ko dest=ja text=こんにちは。 pronunciation=Kon'nichiwa.>\n",
    ">>> translator.translate('veritas lux mea', src='la')\n",
    "# <Translated src=la dest=en text=The truth is my light pronunciation=The truth is my light>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afd0949c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5740\\639053568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Traduzindo para o Inglês\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtextPT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtextEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#traduzindo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0msentimento\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextEN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#obtendo o sentimento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msentimento_bolsonaro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentimento\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#adicionando a uma lista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, text, dest, src)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mdest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLANGCODES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid destination language'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\client.py\u001b[0m in \u001b[0;36m_translate\u001b[1;34m(self, text, dest, src)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice_urls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_translate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'+-a^+6'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'+-3^+b+-f'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m^=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: nocover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m2147483647\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2147483648\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# unescape special ascii characters such like a \\x3d(=)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unicode-escape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "sentimento_bolsonaro = []\n",
    "#Traduzindo para o Inglês\n",
    "for x in textPT:\n",
    "    textEN = Translator().translate(x) #traduzindo\n",
    "    sentimento = TextBlob(textEN.text) #obtendo o sentimento\n",
    "    sentimento_bolsonaro.append(sentimento.polarity) #adicionando a uma lista\n",
    "display(sentimento_bolsonaro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4cd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(sentimento_bolsonaro)\n",
    "display(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134efbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for valor in sentimento_bolsonaro:\n",
    "    if valor > 0: \n",
    "        numPos += 1 \n",
    "    elif valor < 0: \n",
    "        numNeg += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f31e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaPos = numPos/total\n",
    "mediaNeg = numNeg/total\n",
    "print('Porcentagem de comentários positivos: '+str(mediaPos))\n",
    "print('Porcentagem de comentários negativos: '+str(mediaNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b583e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contadores\n",
    "numPos = 0\n",
    "numNeg = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Texto do Tweet\n",
    "textPT = df_lula['Text'].apply(unidecode)\n",
    "display(textPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12015398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimento_lula = []\n",
    "#Traduzindo para o Inglês\n",
    "for x in textPT:\n",
    "    textEN = Translator().translate(x)\n",
    "    sentimento = TextBlob(textEN.text)\n",
    "    sentimento_lula.append(sentimento.polarity)\n",
    "display(sentimento_bolsonaro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e965e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(sentimento_lula)\n",
    "display(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25315f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for valor in sentimento_lula:\n",
    "    if valor > 0: \n",
    "        numPos += 1 \n",
    "    elif valor < 0: \n",
    "        numNeg += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05827d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaPos = numPos/total\n",
    "mediaNeg = numNeg/total\n",
    "print('Porcentagem de comentários positivos: '+str(mediaPos))\n",
    "print('Porcentagem de comentários negativos: '+str(mediaNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
